{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from skopt import gp_minimize\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('../Dataset/movies.csv')\n",
    "ratings = pd.read_csv('../Dataset/ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_data = movies.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove year from title and add to a new column\n",
    "movies_data['year'] = movies_data.title.str.extract(\"\\((\\d{4})\\)\", expand=True)\n",
    "movies_data['year'] = pd.to_datetime(movies_data['year'], format='%Y')\n",
    "movies_data['year'] = movies_data['year'].dt.year\n",
    "movies_data['title'] = movies_data.title.str[:-7]\n",
    "\n",
    "# one hot encoding for genres\n",
    "movies_data = movies_data.join(movies_data.genres.str.get_dummies(sep='|'))\n",
    "                     \n",
    "# create a TF-IDF vectorizer for the titles and insert into the movies dataframe\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "movies_data['title'] = movies_data['title'].str.lower()\n",
    "tfidf_matrix = tfidf.fit_transform(movies_data['title'])\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), index=movies_data.index.tolist())\n",
    "movies_data = pd.concat([movies_data, tfidf_df], axis=1, join='inner').drop(['genres', 'title'], axis=1)\n",
    "\n",
    "# remove movies with the genre 'no genres listed'\n",
    "movies_data = movies_data[movies_data['(no genres listed)'] == 0]\n",
    "movies_data = movies_data.drop('(no genres listed)', axis=1)\n",
    "\n",
    "# remove movies with no year\n",
    "movies_data = movies_data[movies_data['year'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply min-max scaling to the year column\n",
    "scaler = MinMaxScaler()\n",
    "movies_data['year'] = scaler.fit_transform(movies_data[['year']])\n",
    "movies_data['year'] = movies_data['year'].round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_data = movies_data[movies_data.movieId.isin(ratings.movieId.unique())]\n",
    "movies_data.index = movies_data['movieId']\n",
    "movies_data = movies_data.drop('movieId', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings[ratings.movieId.isin(movies_data.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a ratings matrix\n",
    "ratings_matrix = ratings.pivot_table(index=['userId'], columns=['movieId'], values='rating')\n",
    "\n",
    "# get the number of ratings for each user\n",
    "user_counts = pd.DataFrame(ratings_matrix.count(axis=1), columns=['count'])\n",
    "user_counts['userId'] = user_counts.index\n",
    "user_counts = user_counts.sort_values('count', ascending=False)\n",
    "\n",
    "# Fill NaNs with 0\n",
    "ratings_matrix.fillna(0, inplace=True)\n",
    "\n",
    "# order the users by the number of ratings (descending)\n",
    "ratings_matrix = ratings_matrix.reindex(ratings_matrix.astype(bool).sum(axis=1).sort_values(ascending=False).index)\n",
    "\n",
    "# reindex the ratings matrix with the users ordered by the number of ratings\n",
    "ratings_matrix = ratings_matrix.reindex(user_counts.index)\n",
    "\n",
    "# split into (50/20/30) train/(validation/test folds)\n",
    "train, val_test_folds = train_test_split(ratings_matrix, test_size=0.5, random_state=SEED, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_combinations = [(0, 1), (0, 2), (0, 3), (0, 4), (1, 2), (1, 3), (1, 4), (2, 3), (2, 4), (3, 4)]\n",
    "test_combinations = [(2, 3, 4), (1, 3, 4), (1, 2, 4), (1, 2, 3), (0, 3, 4), (0, 2, 4), (0, 2, 3), (0, 1, 4), (0, 1, 3), (0, 1, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the val_test\n",
    "val_test_folds = val_test_folds.sample(frac=1, random_state=SEED)\n",
    "\n",
    "# split into 5 folds for cross validation\n",
    "val_test_folds = np.array_split(val_test_folds, 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    n_neighbors = params[0]\n",
    "    metric = str(params[1])\n",
    "\n",
    "    nearest_neighbors = NearestNeighbors(n_neighbors=n_neighbors, metric=metric, n_jobs=-1)\n",
    "    nearest_neighbors.fit(train.values)\n",
    "\n",
    "    users_precision = []\n",
    "\n",
    "    n = 10\n",
    "\n",
    "    for user in val_set.index:\n",
    "        user_data = val_set.loc[user]\n",
    "        # get the movies the user has rated\n",
    "        rated_movies = user_data[user_data > 0].index.tolist()\n",
    "\n",
    "        rated_movies = ratings.loc[ratings['movieId'].isin(rated_movies) & (ratings['userId'] == user)].sort_values(by=['timestamp'], ascending=False)['movieId'].tolist()\n",
    "\n",
    "        user_movies_watched = rated_movies[:-n]\n",
    "        user_movies_to_predict = rated_movies[-n:]\n",
    "\n",
    "        user_data_temp = user_data.copy()\n",
    "        user_data_temp[user_movies_to_predict] = 0\n",
    "\n",
    "        distances, indices = nearest_neighbors.kneighbors(user_data_temp.values.reshape(1, -1), n_neighbors=n_neighbors)\n",
    "\n",
    "        movies_to_recommend = pd.DataFrame(columns=['recommendations'])\n",
    "        movies_to_recommend['recommendations'] = np.zeros(val_set.shape[1])\n",
    "        movies_to_recommend.index = movies_data.index\n",
    "\n",
    "        # for each neighbor\n",
    "        for i in range(np.shape(indices)[1]):\n",
    "            # get the movies the neighbor has rated\n",
    "            neighbor_rated_movies = train.iloc[indices[0][i]][train.iloc[indices[0][i]] > 0].index.tolist()\n",
    "\n",
    "            for movie in neighbor_rated_movies:\n",
    "                # increment the number of recommendations for the movie\n",
    "                value = movies_to_recommend.at[movie, 'recommendations']\n",
    "                value += 1\n",
    "                movies_to_recommend.loc[movie, 'recommendations'] = value\n",
    "\n",
    "        movies_to_recommend = movies_to_recommend.sort_values(by=['recommendations'], ascending=False)\n",
    "\n",
    "        movies_to_recommend = movies_to_recommend[~movies_to_recommend.index.isin(user_movies_watched)]\n",
    "\n",
    "        movies_to_recommend = movies_to_recommend[:n]\n",
    "\n",
    "        hits = len(set(movies_to_recommend.index.tolist()) & set(user_movies_to_predict))\n",
    "\n",
    "        precision = hits / n\n",
    "\n",
    "        users_precision.append(precision)\n",
    "    \n",
    "    final_precision = np.mean(users_precision)\n",
    "    return 1 - final_precision\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# space=[list(range(3,31)), ['euclidean', 'manhattan', 'cosine']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create csv file\n",
    "# with open('best_FC_NN.csv', 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow([\"val_combination\", \"n_neighbors\", \"metric\", \"precision\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, folds in enumerate(val_combinations):\n",
    "#     val_folds = [val_test_folds[i] for i in folds]\n",
    "#     val_set = pd.concat(val_folds)\n",
    "#     result = gp_minimize(objective, space, verbose=1, n_calls=20, n_random_starts=5, n_jobs=-1, random_state=SEED)\n",
    "\n",
    "#     # save the best parameters\n",
    "#     best_params = {}    \n",
    "#     best_params['n_neighbors'] = result.x[0]\n",
    "#     best_params['metric'] = result.x[1]\n",
    "#     best_params['folds'] = folds\n",
    "#     best_params['precision'] = 1 - result.fun\n",
    "\n",
    "#     # csv file\n",
    "#     with open('best_FC_NN.csv', 'a', newline='') as file:\n",
    "#         writer = csv.writer(file)\n",
    "#         writer.writerow([best_params['folds'], best_params['n_neighbors'], best_params['metric'], best_params['precision']])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = [15,16,15,15,17,29,15,29,16,29]\n",
    "metric = 'cosine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;, metric=&#x27;cosine&#x27;, n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;, metric=&#x27;cosine&#x27;, n_jobs=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(algorithm='brute', metric='cosine', n_jobs=-1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_neighbors = NearestNeighbors(algorithm='brute', metric=metric, n_jobs=-1)\n",
    "nearest_neighbors.fit(train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, folds in enumerate(test_combinations):\n",
    "    # create the test fold\n",
    "    test_folds = [val_test_folds[i] for i in folds]\n",
    "    test_set = pd.concat(test_folds)\n",
    "\n",
    "    users_precision = {}\n",
    "    users_precision[3] = []\n",
    "    users_precision[5] = []\n",
    "    users_precision[10] = []\n",
    "\n",
    "    for user in test_set.index:\n",
    "        user_data = test_set.loc[user]\n",
    "        # get the movies the user has rated\n",
    "        rated_movies = user_data[user_data > 0].index.tolist()\n",
    "\n",
    "        rated_movies = ratings.loc[ratings['movieId'].isin(rated_movies) & (ratings['userId'] == user)].sort_values(by=['timestamp'], ascending=False)['movieId'].tolist()\n",
    "\n",
    "        for n in [3, 5, 10]:\n",
    "            user_movies_watched = rated_movies[:-n]\n",
    "            user_movies_to_predict = rated_movies[-n:]\n",
    "\n",
    "            user_data_temp = user_data.copy()\n",
    "            user_data_temp[user_movies_to_predict] = 0\n",
    "\n",
    "            distances, indices = nearest_neighbors.kneighbors(user_data_temp.values.reshape(1, -1), n_neighbors=n_neighbors[idx])\n",
    "\n",
    "            movies_to_recommend = pd.DataFrame(columns=['recommendations'])\n",
    "            \n",
    "            movies_to_recommend['recommendations'] = np.zeros(test_set.shape[1])\n",
    "            movies_to_recommend.index = movies_data.index\n",
    "\n",
    "            # for each neighbor\n",
    "            for i in range(np.shape(indices)[1]):\n",
    "                # get the movies the neighbor has rated\n",
    "                neighbor_rated_movies = train.iloc[indices[0][i]][train.iloc[indices[0][i]] > 0].index.tolist()\n",
    "                \n",
    "                for movie in neighbor_rated_movies:\n",
    "                    # increment the number of recommendations for the movie\n",
    "                    value = movies_to_recommend.at[movie, 'recommendations']\n",
    "                    value += 1\n",
    "                    movies_to_recommend.loc[movie, 'recommendations'] = value\n",
    "\n",
    "            movies_to_recommend = movies_to_recommend.sort_values(by=['recommendations'], ascending=False)\n",
    "\n",
    "            movies_to_recommend = movies_to_recommend[~movies_to_recommend.index.isin(user_movies_watched)]\n",
    "\n",
    "            movies_to_recommend = movies_to_recommend[:n]\n",
    "\n",
    "            hits = len(set(movies_to_recommend.index.tolist()) & set(user_movies_to_predict))\n",
    "\n",
    "            precision = hits / n\n",
    "\n",
    "            users_precision[n].append(precision)\n",
    "\n",
    "    # save in a file csv - the average and std for each n\n",
    "    for n in [3, 5, 10]:\n",
    "        precision = np.array(users_precision[n])\n",
    "        average = precision.mean()\n",
    "        std = precision.std()\n",
    "        with open('test_FC_nn.csv', 'a') as f:\n",
    "            f.write(f'{folds},{n},{average},{std}\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
