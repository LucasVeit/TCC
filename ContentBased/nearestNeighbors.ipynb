{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from skopt import gp_minimize\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('../Dataset/movies.csv')\n",
    "ratings = pd.read_csv('../Dataset/ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_data = movies.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove year from title and add to a new column\n",
    "movies_data['year'] = movies_data.title.str.extract(\"\\((\\d{4})\\)\", expand=True)\n",
    "movies_data['year'] = pd.to_datetime(movies_data['year'], format='%Y')\n",
    "movies_data['year'] = movies_data['year'].dt.year\n",
    "movies_data['title'] = movies_data.title.str[:-7]\n",
    "\n",
    "# one hot encoding for genres\n",
    "movies_data = movies_data.join(movies_data.genres.str.get_dummies(sep='|'))\n",
    "                     \n",
    "# create a TF-IDF vectorizer for the titles and insert into the movies dataframe\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "movies_data['title'] = movies_data['title'].str.lower()\n",
    "tfidf_matrix = tfidf.fit_transform(movies_data['title'])\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), index=movies_data.index.tolist())\n",
    "movies_data = pd.concat([movies_data, tfidf_df], axis=1, join='inner').drop(['genres', 'title'], axis=1)\n",
    "\n",
    "# remove movies with the genre 'no genres listed'\n",
    "movies_data = movies_data[movies_data['(no genres listed)'] == 0]\n",
    "movies_data = movies_data.drop('(no genres listed)', axis=1)\n",
    "\n",
    "# remove movies with no year\n",
    "movies_data = movies_data[movies_data['year'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply min-max scaling to the year column\n",
    "scaler = MinMaxScaler()\n",
    "movies_data['year'] = scaler.fit_transform(movies_data[['year']])\n",
    "movies_data['year'] = movies_data['year'].round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_data = movies_data[movies_data.movieId.isin(ratings.movieId.unique())]\n",
    "movies_data.index = movies_data['movieId']\n",
    "movies_data = movies_data.drop('movieId', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings[ratings.movieId.isin(movies_data.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a ratings matrix\n",
    "ratings_matrix = ratings.pivot_table(index=['userId'], columns=['movieId'], values='rating')\n",
    "\n",
    "# get the number of ratings for each user\n",
    "user_counts = pd.DataFrame(ratings_matrix.count(axis=1), columns=['count'])\n",
    "user_counts['userId'] = user_counts.index\n",
    "user_counts = user_counts.sort_values('count', ascending=False)\n",
    "\n",
    "# Fill NaNs with 0\n",
    "ratings_matrix.fillna(0, inplace=True)\n",
    "\n",
    "# order the users by the number of ratings (descending)\n",
    "ratings_matrix = ratings_matrix.reindex(ratings_matrix.astype(bool).sum(axis=1).sort_values(ascending=False).index)\n",
    "\n",
    "# reindex the ratings matrix with the users ordered by the number of ratings\n",
    "ratings_matrix = ratings_matrix.reindex(user_counts.index)\n",
    "\n",
    "# split into (50/20/30) train/(validation/test folds)\n",
    "train, val_test_folds = train_test_split(ratings_matrix, test_size=0.5, random_state=SEED, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_combinations = [(0, 1), (0, 2), (0, 3), (0, 4), (1, 2), (1, 3), (1, 4), (2, 3), (2, 4), (3, 4)]\n",
    "test_combinations = [(2, 3, 4), (1, 3, 4), (1, 2, 4), (1, 2, 3), (0, 3, 4), (0, 2, 4), (0, 2, 3), (0, 1, 4), (0, 1, 3), (0, 1, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the val_test\n",
    "val_test_folds = val_test_folds.sample(frac=1, random_state=SEED)\n",
    "\n",
    "# split into 5 folds for cross validation\n",
    "val_test_folds = np.array_split(val_test_folds, 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the objective function to minimize\n",
    "def objective(params):\n",
    "    n_neighbors = params[0]\n",
    "    metric = str(params[1])\n",
    "    nearest_neighbors = NearestNeighbors(n_neighbors=n_neighbors, algorithm='brute', metric=metric, n_jobs=-1)\n",
    "    nearest_neighbors.fit(movies_data.values)\n",
    "\n",
    "    users_precision = []\n",
    "    n = 10\n",
    "\n",
    "    for user in val_set.index:\n",
    "        rated_movies = ratings_matrix.loc[user][ratings_matrix.loc[user] > 0].index.tolist()\n",
    "        \n",
    "        # order the movies by timestamp (ascending)\n",
    "        rated_movies = ratings.loc[\n",
    "            ratings['movieId'].isin(rated_movies) & \n",
    "            (ratings['userId'] == user)].sort_values(\n",
    "                by=['timestamp'], ascending=False\n",
    "                )['movieId'].tolist()\n",
    "    \n",
    "        user_movies_watched = rated_movies[2*-n:-n]\n",
    "        user_movies_to_predict = rated_movies[-n:]\n",
    "\n",
    "        similar_movies = np.zeros(movies_data.shape[0])\n",
    "        mask_similar_movies = np.zeros(movies_data.shape[0])\n",
    "            \n",
    "        data_to_predict = movies_data.loc[user_movies_watched].values\n",
    "\n",
    "        distances, indices = nearest_neighbors.kneighbors(data_to_predict)\n",
    "\n",
    "        for i in range(indices.shape[0]):\n",
    "            for j, idx in enumerate(indices[i]):\n",
    "                mask_similar_movies[idx] = 1\n",
    "                similar_movies[idx] += distances[i][j]\n",
    "                \n",
    "        similar_movies_data = pd.DataFrame()\n",
    "        similar_movies_data.index = movies_data.index\n",
    "        similar_movies_data['distance'] = similar_movies\n",
    "        similar_movies_data['mask'] = mask_similar_movies\n",
    "        similar_movies_data = similar_movies_data[similar_movies_data['mask'] == 1]\n",
    "        similar_movies_data = similar_movies_data.sort_values(by=['distance'], ascending=True)\n",
    "\n",
    "        # remove the movies already watched by the user\n",
    "        similar_movies_data = similar_movies_data[~similar_movies_data.index.isin(user_movies_watched)]\n",
    "\n",
    "        similar_movies_data = similar_movies_data.head(n)\n",
    "\n",
    "        similar_movies = similar_movies_data.index.tolist()\n",
    "\n",
    "        # calculate hits\n",
    "        hits = len(set(similar_movies).intersection(set(user_movies_to_predict)))\n",
    "        \n",
    "        # calculate precision\n",
    "        precision = hits / n\n",
    "        users_precision.append(precision)\n",
    "\n",
    "    final_precision = np.mean(users_precision)\n",
    "    return  1 - final_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# space=[list(range(3,31)), ['euclidean', 'manhattan', 'cosine']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create csv file\n",
    "# with open('best_CB_NN.csv', 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow([\"val_combination\", \"n_neighbors\", \"metric\", \"precision\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, folds in enumerate(val_combinations):\n",
    "#     val_folds = [val_test_folds[i] for i in folds]\n",
    "#     val_set = pd.concat(val_folds)\n",
    "\n",
    "#     result = gp_minimize(objective, space, verbose=1, n_calls=15, n_random_starts=2, n_jobs=-1, random_state=SEED)\n",
    "#     # save the best parameters\n",
    "#     best_params = {}\n",
    "#     best_params['n_neighbors'] = result.x[0]\n",
    "#     best_params['metric'] = result.x[1]\n",
    "#     best_params['folds'] = folds\n",
    "#     best_params['precision'] = 1 - result.fun\n",
    "\n",
    "#     # save the best parameters to a csv file\n",
    "#     with open('best_CB_NN.csv', 'a', newline='') as file:\n",
    "#         writer = csv.writer(file)\n",
    "#         writer.writerow([best_params['folds'], best_params['n_neighbors'], best_params['metric'], best_params['precision']])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = [4, 5, 4, 19, 4, 4, 4, 4, 25, 7]\n",
    "metric = ['euclidean', 'manhattan', 'euclidean', 'cosine', 'euclidean', 'euclidean', 'euclidean', 'euclidean', 'cosine', 'cosine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, folds in enumerate(test_combinations):\n",
    "    # create the test fold\n",
    "    test_folds = [val_test_folds[i] for i in folds]\n",
    "    test_set = pd.concat(test_folds)\n",
    "\n",
    "    users_precision = {}\n",
    "    users_precision[3] = []\n",
    "    users_precision[5] = []\n",
    "    users_precision[10] = []\n",
    "\n",
    "    nearest_neighbors = NearestNeighbors(n_neighbors=n_neighbors[idx] , algorithm='brute', metric=metric[idx], n_jobs=-1)\n",
    "    nearest_neighbors.fit(movies_data.values)\n",
    "\n",
    "    for user in test_set.index:\n",
    "        rated_movies = ratings_matrix.loc[user][ratings_matrix.loc[user] > 0].index.tolist()\n",
    "        \n",
    "        # order the movies by timestamp (ascending)\n",
    "        rated_movies = ratings.loc[\n",
    "            ratings['movieId'].isin(rated_movies) & \n",
    "            (ratings['userId'] == user)].sort_values(\n",
    "                by=['timestamp'], ascending=False\n",
    "                )['movieId'].tolist()\n",
    "        \n",
    "        for n in [3, 5, 10]:\n",
    "        \n",
    "            user_movies_watched = rated_movies[:-n]\n",
    "            user_movies_to_predict = rated_movies[-n:]\n",
    "\n",
    "            similar_movies = np.zeros(movies_data.shape[0])\n",
    "            mask_similar_movies = np.zeros(movies_data.shape[0])\n",
    "            \n",
    "            data_to_predict = movies_data.loc[user_movies_watched[-n:]].values\n",
    "\n",
    "            distances, indices = nearest_neighbors.kneighbors(data_to_predict)\n",
    "\n",
    "            for i in range(indices.shape[0]):\n",
    "                for j, idx in enumerate(indices[i]):\n",
    "                    mask_similar_movies[idx] = 1\n",
    "                    similar_movies[idx] += distances[i][j]\n",
    "                \n",
    "            similar_movies_data = pd.DataFrame()\n",
    "            similar_movies_data.index = movies_data.index\n",
    "            similar_movies_data['distance'] = similar_movies\n",
    "            similar_movies_data['mask'] = mask_similar_movies\n",
    "            similar_movies_data = similar_movies_data[similar_movies_data['mask'] == 1]\n",
    "            similar_movies_data = similar_movies_data.sort_values(by=['distance'], ascending=True)\n",
    "\n",
    "            # remove the movies already watched by the user\n",
    "            similar_movies_data = similar_movies_data[~similar_movies_data.index.isin(user_movies_watched)]\n",
    "\n",
    "            similar_movies_data = similar_movies_data.head(n)\n",
    "\n",
    "            similar_movies = similar_movies_data.index.tolist()\n",
    "\n",
    "            # calculate hits\n",
    "            hits = len(set(similar_movies).intersection(set(user_movies_to_predict)))\n",
    "            \n",
    "            # calculate precision\n",
    "            precision = hits / n\n",
    "            users_precision[n].append(precision)\n",
    "\n",
    "    # save in a file csv - the average and std for each n\n",
    "    for n in [3, 5, 10]:\n",
    "        precision = np.array(users_precision[n])\n",
    "        average = precision.mean()\n",
    "        std = precision.std()\n",
    "        with open('test_CB_nn.csv', 'a') as f:\n",
    "            f.write(f'{folds},{n},{average},{std}\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
