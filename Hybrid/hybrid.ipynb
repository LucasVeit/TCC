{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from skopt import gp_minimize\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('../Dataset/movies.csv')\n",
    "ratings = pd.read_csv('../Dataset/ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_data = movies.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove year from title and add to a new column\n",
    "movies_data['year'] = movies_data.title.str.extract(\"\\((\\d{4})\\)\", expand=True)\n",
    "movies_data['year'] = pd.to_datetime(movies_data['year'], format='%Y')\n",
    "movies_data['year'] = movies_data['year'].dt.year\n",
    "movies_data['title'] = movies_data.title.str[:-7]\n",
    "\n",
    "# one hot encoding for genres\n",
    "movies_data = movies_data.join(movies_data.genres.str.get_dummies(sep='|'))\n",
    "                     \n",
    "# create a TF-IDF vectorizer for the titles and insert into the movies dataframe\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "movies_data['title'] = movies_data['title'].str.lower()\n",
    "tfidf_matrix = tfidf.fit_transform(movies_data['title'])\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), index=movies_data.index.tolist())\n",
    "movies_data = pd.concat([movies_data, tfidf_df], axis=1, join='inner').drop(['genres', 'title'], axis=1)\n",
    "\n",
    "# remove movies with the genre 'no genres listed'\n",
    "movies_data = movies_data[movies_data['(no genres listed)'] == 0]\n",
    "movies_data = movies_data.drop('(no genres listed)', axis=1)\n",
    "\n",
    "# remove movies with no year\n",
    "movies_data = movies_data[movies_data['year'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply min-max scaling to the year column\n",
    "scaler = MinMaxScaler()\n",
    "movies_data['year'] = scaler.fit_transform(movies_data[['year']])\n",
    "movies_data['year'] = movies_data['year'].round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_data = movies_data[movies_data.movieId.isin(ratings.movieId.unique())]\n",
    "movies_data.index = movies_data['movieId']\n",
    "movies_data = movies_data.drop('movieId', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings[ratings.movieId.isin(movies_data.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a ratings matrix\n",
    "ratings_matrix = ratings.pivot_table(index=['userId'], columns=['movieId'], values='rating')\n",
    "\n",
    "# get the number of ratings for each user\n",
    "user_counts = pd.DataFrame(ratings_matrix.count(axis=1), columns=['count'])\n",
    "user_counts['userId'] = user_counts.index\n",
    "user_counts = user_counts.sort_values('count', ascending=False)\n",
    "\n",
    "# Fill NaNs with 0\n",
    "ratings_matrix.fillna(0, inplace=True)\n",
    "\n",
    "# order the users by the number of ratings (descending)\n",
    "ratings_matrix = ratings_matrix.reindex(ratings_matrix.astype(bool).sum(axis=1).sort_values(ascending=False).index)\n",
    "\n",
    "# reindex the ratings matrix with the users ordered by the number of ratings\n",
    "ratings_matrix = ratings_matrix.reindex(user_counts.index)\n",
    "\n",
    "# split into (50/20/30) train/(validation/test folds)\n",
    "train, val_test_folds = train_test_split(ratings_matrix, test_size=0.5, random_state=SEED, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_combinations = [(0, 1), (0, 2), (0, 3), (0, 4), (1, 2), (1, 3), (1, 4), (2, 3), (2, 4), (3, 4)]\n",
    "test_combinations = [(2, 3, 4), (1, 3, 4), (1, 2, 4), (1, 2, 3), (0, 3, 4), (0, 2, 4), (0, 2, 3), (0, 1, 4), (0, 1, 3), (0, 1, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the val_test\n",
    "val_test_folds = val_test_folds.sample(frac=1, random_state=SEED)\n",
    "\n",
    "# split into 5 folds for cross validation\n",
    "val_test_folds = np.array_split(val_test_folds, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_nearest_neighbors = NearestNeighbors(algorithm='brute', metric='cosine', n_jobs=-1)\n",
    "cf_nearest_neighbors.fit(train.values)\n",
    "cf_n_neighbors = [15,16,15,15,17,29,15,29,16,29]\n",
    "\n",
    "def cf(user_movies_watched, user_data_temp, idx):\n",
    "    distances, indices = cf_nearest_neighbors.kneighbors(user_data_temp.values.reshape(1, -1), n_neighbors=cf_n_neighbors[idx])\n",
    "\n",
    "    movies_to_recommend = pd.DataFrame(columns=['recommendations'])\n",
    "    movies_to_recommend['recommendations'] = np.zeros(test_set.shape[1])\n",
    "    movies_to_recommend.index = movies_data.index\n",
    "\n",
    "    \n",
    "    # for each neighbor\n",
    "    for i in range(np.shape(indices)[1]):\n",
    "        # get the movies the neighbor has rated\n",
    "        neighbor_rated_movies = train.iloc[indices[0][i]][train.iloc[indices[0][i]] > 0].index.tolist()\n",
    "        \n",
    "        for movie in neighbor_rated_movies:\n",
    "            # increment the number of recommendations for the movie\n",
    "            value = movies_to_recommend.at[movie, 'recommendations']\n",
    "            value += 1\n",
    "            movies_to_recommend.loc[movie, 'recommendations'] = value\n",
    "\n",
    "\n",
    "    movies_to_recommend = movies_to_recommend.sort_values(by=['recommendations'], ascending=False)\n",
    "\n",
    "    movies_to_recommend = movies_to_recommend[~movies_to_recommend.index.isin(user_movies_watched)]\n",
    "\n",
    "    movies_to_recommend = movies_to_recommend[:30]\n",
    "\n",
    "    return movies_to_recommend.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_n_neighbors = [4, 5, 4, 19, 4, 4, 4, 4, 25, 7]\n",
    "cb_metric = ['euclidean', 'manhattan', 'euclidean', 'cosine', 'euclidean', 'euclidean', 'euclidean', 'euclidean', 'cosine', 'cosine']\n",
    "\n",
    "def cb(n, user_movies_watched, idx):\n",
    "     cb_nearest_neighbors = NearestNeighbors(n_neighbors=cb_n_neighbors[idx] , algorithm='brute', metric=cb_metric[idx], n_jobs=-1)\n",
    "     cb_nearest_neighbors.fit(movies_data.values)\n",
    "\n",
    "\n",
    "     similar_movies = np.zeros(movies_data.shape[0])\n",
    "     mask_similar_movies = np.zeros(movies_data.shape[0])\n",
    "          \n",
    "     data_to_predict = movies_data.loc[user_movies_watched[-n:]].values\n",
    "\n",
    "     distances, indices = cb_nearest_neighbors.kneighbors(data_to_predict)\n",
    "\n",
    "     for i in range(indices.shape[0]):\n",
    "          for j, idx in enumerate(indices[i]):\n",
    "               mask_similar_movies[idx] = 1\n",
    "               similar_movies[idx] += distances[i][j]\n",
    "                \n",
    "     similar_movies_data = pd.DataFrame()\n",
    "     similar_movies_data.index = movies_data.index\n",
    "     similar_movies_data['distance'] = similar_movies\n",
    "     similar_movies_data['mask'] = mask_similar_movies\n",
    "     similar_movies_data = similar_movies_data[similar_movies_data['mask'] == 1]\n",
    "     similar_movies_data = similar_movies_data.sort_values(by=['distance'], ascending=True)\n",
    "\n",
    "     \n",
    "     similar_movies_data = similar_movies_data[~similar_movies_data.index.isin(user_movies_watched)]\n",
    "\n",
    "     similar_movies_data = similar_movies_data.head(30)\n",
    "\n",
    "     similar_movies = similar_movies_data.index.tolist()\n",
    "\n",
    "     return similar_movies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, folds in enumerate(test_combinations):\n",
    "    test_folds = [val_test_folds[i] for i in folds]\n",
    "    test_set = pd.concat(test_folds)\n",
    "\n",
    "    users_precision = {}\n",
    "    users_precision[3] = []\n",
    "    users_precision[5] = []\n",
    "    users_precision[10] = []\n",
    "\n",
    "    for user in test_set.index:\n",
    "        user_data = test_set.loc[user]\n",
    "        \n",
    "        rated_movies = ratings_matrix.loc[user][ratings_matrix.loc[user] > 0].index.tolist()\n",
    "        \n",
    "        # order the movies by timestamp (ascending)\n",
    "        rated_movies = ratings.loc[\n",
    "            ratings['movieId'].isin(rated_movies) & \n",
    "            (ratings['userId'] == user)].sort_values(\n",
    "                by=['timestamp'], ascending=False\n",
    "                )['movieId'].tolist()\n",
    "        \n",
    "        for n in [3, 5, 10]:\n",
    "            # For Both\n",
    "            user_movies_watched = rated_movies[:-n]\n",
    "            user_movies_to_predict = rated_movies[-n:]\n",
    "\n",
    "            # For CF\n",
    "            user_data_temp = user_data.copy()\n",
    "            user_data_temp[user_movies_to_predict] = 0\n",
    "\n",
    "            cf_top30 = cf(user_movies_watched, user_data_temp, idx)\n",
    "            cb_top30 = cb(n, user_movies_watched, idx)\n",
    "\n",
    "            cf_top30 = cf_top30[::-1]\n",
    "            cb_top30 = cb_top30[::-1]\n",
    "\n",
    "            cf_top30 = pd.DataFrame(cf_top30, columns=['movieId'])\n",
    "            cb_top30 = pd.DataFrame(cb_top30, columns=['movieId'])\n",
    "\n",
    "            movies_cb = np.shape(cb_top30)[0]\n",
    "            movies_cf = np.shape(cf_top30)[0]\n",
    "\n",
    "            cf_top30['weight'] = np.arange(30, 30 - movies_cf, -1)\n",
    "            cb_top30['weight'] = np.arange(30, 30 - movies_cb, -1) \n",
    "\n",
    "            # ponderate the scores 70% for cf and 30% for bc\n",
    "            cf_top30['weight'] = cf_top30['weight'] * 0.7\n",
    "            cb_top30['weight'] = cb_top30['weight'] * 0.3\n",
    "\n",
    "            # create the hybrid list\n",
    "            hybrid_list = pd.concat([cf_top30, cb_top30])\n",
    "            hybrid_list = hybrid_list.groupby(['movieId']).sum()\n",
    "\n",
    "            # order the hybrid list by score (descending)\n",
    "            hybrid_list = hybrid_list.sort_values(by=['weight'], ascending=False)\n",
    "\n",
    "            # get the top n movies from the hybrid recommender\n",
    "            hybrid_list = hybrid_list.index.tolist()\n",
    "            hybrid_list = hybrid_list[:n]\n",
    "\n",
    "            # calculate the precision\n",
    "            hits = len(set(hybrid_list).intersection(set(user_movies_to_predict)))\n",
    "\n",
    "            precision = hits / n\n",
    "\n",
    "            users_precision[n].append(precision)\n",
    "    \n",
    "    for n in [3, 5, 10]:\n",
    "        precision = np.array(users_precision[n])\n",
    "        average = precision.mean()\n",
    "        std = precision.std()\n",
    "\n",
    "        with open('test_hybrid_nn.csv', 'a') as f:\n",
    "            f.write(f'{folds},{n},{average},{std}\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
